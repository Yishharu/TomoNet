{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pyvtk\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from netCDF4 import Dataset\n",
    "import shutil\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data structure in element-wise output is too complicated for xarray.open_mfdataset.\n",
    "# Here we open the files as individual datasets and concatenate them on the variable level.\n",
    "# This code is compatible with parallel netcdf build (single file output)\n",
    "\n",
    "# load_wave_data=True:  read wave data and return numpy.ndarray\n",
    "# load_wave_data=False: do not read wave data and return xarray.DataArray (use False if data is big)\n",
    "\n",
    "def read_element_output(data_dir, load_wave_data=True):\n",
    "    ################ open files ################\n",
    "    # filenames\n",
    "    nc_fnames = [f for f in os.listdir(data_dir) if 'axisem3d_synthetics.nc' in f]\n",
    "    # print('files to open: ', nc_fnames)\n",
    "\n",
    "    # open files\n",
    "    nc_files = []\n",
    "    for nc_fname in nc_fnames:\n",
    "        nc_files.append(xr.open_dataset(data_dir + '/' + nc_fname))\n",
    "    \n",
    "    ################ variables that are the same in the datasets ################\n",
    "    # read Na grid (all azimuthal dimensions)\n",
    "    na_grid = nc_files[0].data_vars['list_na_grid'].values.astype(int)\n",
    "\n",
    "    # read time\n",
    "    data_time = nc_files[0].data_vars['data_time'].values\n",
    "    \n",
    "    \n",
    "    ################ variables to be concatenated over the datasets ################\n",
    "    # define empty lists of xarray.DataArray objects\n",
    "    xda_list_element_na = []\n",
    "    xda_list_element_coords = []\n",
    "    dict_xda_list_element = {}\n",
    "    dict_xda_data_wave = {}\n",
    "    for nag in na_grid:\n",
    "        dict_xda_list_element[nag] = []\n",
    "        dict_xda_data_wave[nag] = []\n",
    "    \n",
    "    # loop over nc files\n",
    "    for nc_file in nc_files:\n",
    "        # append DataArrays\n",
    "        xda_list_element_na.append(nc_file.data_vars['list_element_na'])\n",
    "        xda_list_element_coords.append(nc_file.data_vars['list_element_coords'])\n",
    "        for nag in na_grid:\n",
    "            dict_xda_list_element[nag].append(nc_file.data_vars['list_element__NaG=%d' % nag])\n",
    "            dict_xda_data_wave[nag].append(nc_file.data_vars['data_wave__NaG=%d' % nag])\n",
    "            \n",
    "    # concat xarray.DataArray\n",
    "    xda_list_element_na = xr.concat(xda_list_element_na, dim='dim_element')\n",
    "    xda_list_element_coords = xr.concat(xda_list_element_coords, dim='dim_element')\n",
    "    for nag in na_grid:\n",
    "        dict_xda_list_element[nag] = xr.concat(dict_xda_list_element[nag], dim='dim_element__NaG=%d' % nag)\n",
    "        dict_xda_data_wave[nag] = xr.concat(dict_xda_data_wave[nag], dim='dim_element__NaG=%d' % nag)\n",
    "        \n",
    "    # read data to numpy.ndarray\n",
    "    list_element_na = xda_list_element_na.values.astype(int)\n",
    "    list_element_coords = xda_list_element_coords.values\n",
    "    dict_list_element = {}\n",
    "    dict_data_wave = {}\n",
    "    for nag in na_grid:\n",
    "        dict_list_element[nag] = dict_xda_list_element[nag].values.astype(int)\n",
    "        if load_wave_data:\n",
    "            dict_data_wave[nag] = dict_xda_data_wave[nag].values\n",
    "        \n",
    "    ############### return ################\n",
    "    if load_wave_data:\n",
    "        return na_grid, data_time, list_element_na, list_element_coords, dict_list_element, dict_data_wave\n",
    "    else:\n",
    "        return na_grid, data_time, list_element_na, list_element_coords, dict_list_element, dict_xda_data_wave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inplane slices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data dir\n",
    "# ModelNameList = ['model0021']\n",
    "ModelNameList = []\n",
    "for imodel in [3000]:\n",
    "    ModeName = 'LatinSphericalHarmonicsAcousticBall%04d' %imodel\n",
    "    ModelNameList.append(ModeName)\n",
    "    \n",
    "# wave dimension to animation\n",
    "output_channel = 'X'\n",
    "wave_dim_X = output_channel.index('X')\n",
    "\n",
    "# output_channel = 'Xspz'\n",
    "# wave_dim_s = output_channel.index('s')\n",
    "# wave_dim_p = output_channel.index('p')\n",
    "# wave_dim_z = output_channel.index('z')\n",
    "# wave_dim_X = output_channel.index('X')\n",
    "\n",
    "for ModelName in ModelNameList:\n",
    "    data_dir = '../Runs/%s/output/elements/azimuthal_slices' %ModelName\n",
    "    \n",
    "    if not os.path.exists(data_dir):\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # read\n",
    "        na_grid, data_time, list_element_na, list_element_coords, \\\n",
    "        dict_list_element, dict_data_wave = read_element_output(data_dir)\n",
    "    except:\n",
    "        print(ModelName, \"reading error!!!!!\")\n",
    "        continue\n",
    "\n",
    "    # time steps\n",
    "    ntime = len(data_time)\n",
    "\n",
    "    # phi of the slices\n",
    "    phi_slices = [0.        , 0.39269908, 0.78539816, 1.17809725, 1.57079633, 1.96349541, 2.35619449, 2.74889357, 3.14159265, 3.53429174, 3.92699082, 4.3196899 , 4.71238898, 5.10508806, 5.49778714, 5.89048623]\n",
    "\n",
    "    nslice = len(phi_slices)\n",
    "\n",
    "    # GLL coords on elements\n",
    "    nelem = list_element_coords.shape[0]\n",
    "    ngll = list_element_coords.shape[1]\n",
    "    # flattened coords, (s, z)\n",
    "    element_coords_sz = list_element_coords.reshape((nelem * ngll), 2)\n",
    "\n",
    "    # loop over slices\n",
    "    # for islice, phi in enumerate(phi_slices):\n",
    "    islice = 1\n",
    "\n",
    "    phi = phi_slices[islice]\n",
    "    # vtk mesh\n",
    "    xyz = np.ndarray((nelem * ngll, 3))\n",
    "    xyz[:, 0] = element_coords_sz[:, 0] * np.cos(phi)\n",
    "    xyz[:, 1] = element_coords_sz[:, 0] * np.sin(phi)\n",
    "    xyz[:, 2] = element_coords_sz[:, 1]\n",
    "\n",
    "\n",
    "    wave_X = np.ndarray((nelem * ngll, ntime))\n",
    "\n",
    "    # check singlar value \n",
    "    if wave_X.max() > 100:\n",
    "        print(wave_X.max(), '%s Singular vale!!!!!' %ModelName)\n",
    "        print(ModelName, phi)\n",
    "        continue\n",
    "\n",
    "\n",
    "    for ielem in np.arange(nelem):\n",
    "        # wave_s[(ielem * ngll):(ielem * ngll + ngll), :] = dict_data_wave[nslice][ielem, islice, :, wave_dim_s, :]\n",
    "        # wave_p[(ielem * ngll):(ielem * ngll + ngll), :] = dict_data_wave[nslice][ielem, islice, :, wave_dim_p, :]\n",
    "        # wave_z[(ielem * ngll):(ielem * ngll + ngll), :] = dict_data_wave[nslice][ielem, islice, :, wave_dim_z, :]\n",
    "\n",
    "        wave_X[(ielem * ngll):(ielem * ngll + ngll), :] = dict_data_wave[nslice][ielem, islice, :, wave_dim_X, :]\n",
    "        \n",
    "        # # loop over time to write netcdf\n",
    "        # for itime in np.arange(ntime):\n",
    "\n",
    "        #     # if itime<50 or itime>55:\n",
    "        #     #     continue\n",
    "\n",
    "        #     # make slice for phi\n",
    "        #     NETCDFDir = data_dir + '/netcdf_slices/time%d' % itime\n",
    "        #     os.makedirs(NETCDFDir, exist_ok=True)\n",
    "\n",
    "        #     nc = Dataset(NETCDFDir+'/phi_slice%d.nc' %islice, 'w')\n",
    "        #     nc.createDimension('npoint', size=len(xyz))\n",
    "        #     nc.createDimension('d3', size=3)\n",
    "        #     # nc.createDimension('ntime', size=ntime)\n",
    "\n",
    "        #     nc.createVariable('element_coords_cartesian', float, dimensions=('npoint','d3'))\n",
    "        #     nc['element_coords_cartesian'][:,:] = xyz[:,:]\n",
    "\n",
    "        #     # nc.createVariable('time', float, dimensions=('ntime'))\n",
    "        #     # nc['time'][:] = data_time[:]\n",
    "\n",
    "        #     nc.createVariable('X', float, dimensions=('npoint'))\n",
    "        #     nc['X'][:] = wave_X[:,itime]\n",
    "\n",
    "        #     nc.close()\n",
    "\n",
    "            # # make slice for disp\n",
    "            # NETCDFDir = data_dir + '/netcdf/snapshot%d' % itime\n",
    "            # os.makedirs(NETCDFDir, exist_ok=True)\n",
    "\n",
    "            # nc = Dataset(NETCDFDir+'/disp_slice%d.nc' %islice, 'w')\n",
    "            # nc.createDimension('npoint', size=len(xyz))\n",
    "            # nc.createDimension('3D', size=3)\n",
    "\n",
    "            # nc.createVariable('x', float, dimensions=('npoint'))\n",
    "            # nc['x'][:] = xyz[:,0]\n",
    "            # nc.createVariable('y', float, dimensions=('npoint'))\n",
    "            # nc['y'][:] = xyz[:,1]\n",
    "            # nc.createVariable('z', float, dimensions=('npoint'))\n",
    "            # nc['z'][:] = xyz[:,2]\n",
    "            # nc.createVariable('time', float, dimensions=('npoint'))\n",
    "            # nc['time'][:] = np.ones(len(xyz))*data_time[itime]\n",
    "\n",
    "            # # convert spz to xyz coordinate frame by formula 3.9 Leng thesis page 28\n",
    "            # nc.createVariable('disp_x', float, dimensions=('npoint'))\n",
    "            # nc['disp_x'][:] = wave_s[:,itime] * np.cos(phi) - wave_p[:,itime] * np.sin(phi)\n",
    "            # nc.createVariable('disp_y', float, dimensions=('npoint'))\n",
    "            # nc['disp_y'][:] = wave_s[:,itime] * np.sin(phi) + wave_p[:,itime] * np.cos(phi)\n",
    "            # nc.createVariable('disp_z', float, dimensions=('npoint'))\n",
    "            # nc['disp_z'][:] = wave_z[:,itime]\n",
    "\n",
    "            # nc.close()\n",
    "\n",
    "    #         print('Done time step %d / %d' % (itime + 1, ntime), end='\\r')\n",
    "    #     print('\\nDone slice %d / %d' % (islice + 1, len(phi_slices)))\n",
    "\n",
    "    # # # Check Repeated Dataset\n",
    "    # # if os.path.exists('../DataSet/%s/' %ModelName):\n",
    "    # #     shutil.rmtree('../DataSet/%s/' %ModelName)\n",
    "\n",
    "    # # Initial Model Folder\n",
    "    # os.makedirs('../DataSet/%s/' %ModelName, exist_ok=True)\n",
    "\n",
    "    # # Check 3D model nc file\n",
    "    # NCFilePath = glob.glob('../Runs/%s/input/*.nc' %ModelName)\n",
    "    # if len(NCFilePath) > 0:\n",
    "    #     for path in NCFilePath:\n",
    "    #         shutil.copy(path, '../DataSet/%s/' %ModelName)\n",
    "    # # Move Spherical Harmonics Paramters\n",
    "    # SphericalHarmonicsPath = glob.glob('../Runs/%s/Spherical_Harmonics.pkl' %ModelName)[0]\n",
    "    # shutil.copy(SphericalHarmonicsPath, '../DataSet/%s/' %ModelName)\n",
    "\n",
    "    # target_dir = '../DataSet/%s/snapshot/' %ModelName\n",
    "    # if os.path.exists(target_dir):\n",
    "    #     shutil.rmtree(target_dir)\n",
    "    # shutil.move(data_dir + '/netcdf_slices/', target_dir)\n",
    "\n",
    "    # print(data_dir + '/netcdf_slices/', '../DataSet/%s/snapshot' %ModelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3648, 16, 1, 1, 15)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_data_wave[nslice].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phi:  0.39269908\n",
      "element_coords_sz:  [378.13297608 266.31128853]\n",
      "xyz :  [349.34931742 144.70522458 266.31128853]\n",
      "wave_X :  -6.81324863194277e-08\n"
     ]
    }
   ],
   "source": [
    "itime = 10\n",
    "np.shape(element_coords_sz), np.shape(xyz), np.shape(wave_X[:,itime])\n",
    "\n",
    "i_test_element = 100\n",
    "print('phi: ', phi)\n",
    "print('element_coords_sz: ', element_coords_sz[i_test_element,:])\n",
    "print('xyz : ', xyz[i_test_element,:])\n",
    "print('wave_X : ', wave_X[i_test_element, itime])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b5da1a19760c645bef876c945e2def5171d007c0fd3f14585be32e516ddabd56"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
