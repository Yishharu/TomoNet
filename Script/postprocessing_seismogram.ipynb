{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import shutil \n",
    "from netCDF4 import Dataset\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from obspy.core import Stream, Trace, UTCDateTime, Stats\n",
    "from obspy.core.event import read_events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/raid1/TomoNet/Runs/Sample/globalmodel0013/seismogram.nc  set up and saved!\n"
     ]
    }
   ],
   "source": [
    "ModelName = 'globalmodel0013'\n",
    "RunPath = './Runs/%s' %ModelName\n",
    "\n",
    "NETCDFDir = '/raid1/TomoNet/Runs/Sample/%s' %ModelName\n",
    "if not os.path.exists(NETCDFDir):\n",
    "    os.mkdir(NETCDFDir)\n",
    "StationInfo = np.loadtxt(RunPath+'/input/Synthetic_Stations',dtype=str, skiprows=1)\n",
    "stalatlon_dict = {}\n",
    "for item in StationInfo:\n",
    "    stkey = item[1]+'.'+item[0]\n",
    "    lat = float(item[2])\n",
    "    lon = float(item[3])\n",
    "    if stkey not in stalatlon_dict.keys():\n",
    "        stalatlon_dict[stkey] = []\n",
    "    stalatlon_dict[stkey].append((lat, lon))\n",
    "\n",
    "# from obspy.taup import TauPyModel\n",
    "# model = TauPyModel(model=\"prem\")\n",
    "# OUTPUTFormat = 'Default'\n",
    "\n",
    "StartTime, EndTime = 0, 3000\n",
    "resample_rate = 1.\n",
    "lowpass_freq = 1/50\n",
    "\n",
    "PointPerTrace = int((EndTime - StartTime)/resample_rate)+1\n",
    "\n",
    "istation = 0\n",
    "\n",
    "if os.path.exists(NETCDFDir+'/seismogram.nc'):\n",
    "    os.remove(NETCDFDir+'/seismogram.nc')\n",
    "nc = Dataset(NETCDFDir+'/seismogram.nc', 'w')\n",
    "nc.createDimension('npoint', size=PointPerTrace*len(stalatlon_dict))\n",
    "nc.createVariable('x', float, dimensions=('npoint'))\n",
    "nc.createVariable('y', float, dimensions=('npoint'))\n",
    "nc.createVariable('z', float, dimensions=('npoint'))\n",
    "nc.createVariable('time', float, dimensions=('npoint'))\n",
    "nc.createVariable('disp_x', float, dimensions=('npoint'))\n",
    "nc.createVariable('disp_y', float, dimensions=('npoint'))\n",
    "nc.createVariable('disp_z', float, dimensions=('npoint'))\n",
    "\n",
    "\n",
    "GSNDir = RunPath + '/output/stations/Synthetic_Stations'\n",
    "\n",
    "# read rank-station info\n",
    "rank_station_info = np.loadtxt(GSNDir + '/rank_station.info', dtype=str, skiprows=1)\n",
    "\n",
    "# dict: mpi-rank -> [station keys]\n",
    "rank_station_dict = {}\n",
    "for item in rank_station_info:\n",
    "    rank = item[0]\n",
    "    stkey = item[1]\n",
    "    inrank_index = item[2]\n",
    "    # initialize with an empty array if rank does not exists in rank_station_dict\n",
    "    if rank not in rank_station_dict.keys():\n",
    "        rank_station_dict[rank] = []\n",
    "    # append the station\n",
    "    rank_station_dict[rank].append([stkey, inrank_index])\n",
    "        \n",
    "# loop over mpi-ranks to read data\n",
    "for rank in rank_station_dict.keys():\n",
    "    f = Dataset(GSNDir + '/axisem3d_synthetics.nc.rank%s' %rank, 'r')\n",
    "    time = f.variables['data_time'][:]\n",
    "\n",
    "    for [StationName, inrank_index] in rank_station_dict[rank]:\n",
    "\n",
    "        lat, lon = stalatlon_dict[StationName][0][0], stalatlon_dict[StationName][0][1]\n",
    "        colat = 90 - lat\n",
    "\n",
    "        theta = np.radians(colat)\n",
    "        phi = np.radians(lon)\n",
    "\n",
    "        stax = 6371e3*np.sin(theta)*np.cos(phi)\n",
    "        stay = 6371e3*np.sin(theta)*np.sin(phi)\n",
    "        staz = 6371e3*np.cos(theta)\n",
    "\n",
    "        # trace header\n",
    "        stats = Stats()\n",
    "        stats.starttime = UTCDateTime(time[0])\n",
    "        stats.delta = UTCDateTime(time[1] - time[0])\n",
    "        stats.npts = len(time)\n",
    "\n",
    "        # stream\n",
    "        stream = Stream()\n",
    "        for ich, ch in enumerate('spz'):\n",
    "            stats.channel = ch  \n",
    "            # default unit is km\n",
    "            stream.append(Trace(f.variables['data_wave'][int(inrank_index)][ich], header=stats))\n",
    "\n",
    "        # arrivals = model.get_travel_times(source_depth_in_km=400,\n",
    "        #                                 distance_in_degree=colat,\n",
    "        #                                 phase_list=[\"P\", \"Pdiff\"])\n",
    "        # arrivals[0].time\n",
    "        # process (filter, resample, slice, ...)\n",
    "        stream.filter('lowpass', freq=lowpass_freq)\n",
    "        stream.resample(resample_rate)\n",
    "        # stream = stream.slice(UTCDateTime(int(arrivals[0].time)+StartTime), UTCDateTime(int(arrivals[0].time)+EndTime))\n",
    "        stream = stream.slice(UTCDateTime(StartTime), UTCDateTime(EndTime))\n",
    "        npoint_persta = len(stream[0].data)\n",
    "       \n",
    "        nc['x'][istation*npoint_persta:(istation+1)*npoint_persta] = stax * np.ones(npoint_persta)\n",
    "        nc['y'][istation*npoint_persta:(istation+1)*npoint_persta] = stay * np.ones(npoint_persta)\n",
    "        nc['z'][istation*npoint_persta:(istation+1)*npoint_persta] = staz * np.ones(npoint_persta)\n",
    "\n",
    "        # nc['time'][istation*npoint_persta:(istation+1)*npoint_persta] = stream[0].times() + int(arrivals[0].time) + StartTime\n",
    "        nc['time'][istation*npoint_persta:(istation+1)*npoint_persta] = stream[0].times()\n",
    "\n",
    "        nc['disp_x'][istation*npoint_persta:(istation+1)*npoint_persta] = stream[0].data * np.cos(phi) - stream[1].data * np.sin(phi)\n",
    "        nc['disp_y'][istation*npoint_persta:(istation+1)*npoint_persta] = stream[0].data * np.sin(phi) + stream[1].data * np.cos(phi)\n",
    "        nc['disp_z'][istation*npoint_persta:(istation+1)*npoint_persta] = stream[2].data\n",
    "\n",
    "        istation += 1\n",
    "# # print & plot\n",
    "# print(stream)\n",
    "# stream.plot()\n",
    "# nc.createVariable('time', float, dimensions=('npoint'))\n",
    "# nc['time'][:] = stream[0].times()\n",
    "nc.close()\n",
    "\n",
    "print(NETCDFDir+'/seismogram.nc', \" set up and saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npoint_persta\n",
    "PointPerTrace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/raid1/TomoNet/Runs/Sample/model0011/UnifromEarthCore.bm'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "# Move netcdf file\n",
    "# shutil.copy(RunPath+'/input/box_tomography.nc',NETCDFDir)\n",
    "shutil.copy(RunPath+'/tools/UnifromEarthCore.bm',NETCDFDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b5da1a19760c645bef876c945e2def5171d007c0fd3f14585be32e516ddabd56"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
