{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import shutil \n",
    "from netCDF4 import Dataset\n",
    "import numpy as np\n",
    "import os\n",
    "import yaml \n",
    "\n",
    "from obspy.core import Stream, Trace, UTCDateTime, Stats\n",
    "from obspy.core.event import read_events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read event location\n",
    "# with open('../Runs/CartesianModel0007_random0000/input/inparam.output.yaml', 'r') as file:\n",
    "    output_yaml = yaml.load(file, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1.5]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output_yaml['list_of_station_groups'][0]['Synthetic_Stations']['temporal']['time_window']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../DataSet/CartesianModel0007_random0000/seismogram.nc  set up and saved!\n",
      "../DataSet/CartesianModel0007_random0001/seismogram.nc  set up and saved!\n",
      "../DataSet/CartesianModel0007_random0002/seismogram.nc  set up and saved!\n",
      "../DataSet/CartesianModel0007_random0003/seismogram.nc  set up and saved!\n",
      "../DataSet/CartesianModel0007_random0004/seismogram.nc  set up and saved!\n",
      "../DataSet/CartesianModel0007_random0005/seismogram.nc  set up and saved!\n",
      "../DataSet/CartesianModel0007_random0006/seismogram.nc  set up and saved!\n",
      "../DataSet/CartesianModel0007_random0007/seismogram.nc  set up and saved!\n",
      "../DataSet/CartesianModel0007_random0008/seismogram.nc  set up and saved!\n",
      "../DataSet/CartesianModel0007_random0009/seismogram.nc  set up and saved!\n",
      "../DataSet/CartesianModel0007_random0010/seismogram.nc  set up and saved!\n",
      "../DataSet/CartesianModel0007_random0011/seismogram.nc  set up and saved!\n",
      "../DataSet/CartesianModel0007_random0012/seismogram.nc  set up and saved!\n",
      "../DataSet/CartesianModel0007_random0013/seismogram.nc  set up and saved!\n",
      "../DataSet/CartesianModel0007_random0014/seismogram.nc  set up and saved!\n",
      "../DataSet/CartesianModel0007_random0015/seismogram.nc  set up and saved!\n",
      "../DataSet/CartesianModel0007_random0016/seismogram.nc  set up and saved!\n",
      "../DataSet/CartesianModel0007_random0017/seismogram.nc  set up and saved!\n",
      "../DataSet/CartesianModel0007_random0018/seismogram.nc  set up and saved!\n",
      "../DataSet/CartesianModel0007_random0019/seismogram.nc  set up and saved!\n",
      "../DataSet/CartesianModel0007_random0020/seismogram.nc  set up and saved!\n"
     ]
    }
   ],
   "source": [
    "# data dir\n",
    "# ModelNameList = ['CartesianModel0007_5pct','CartesianModel0007_10pct','CartesianModel0007_20pct']\n",
    "ModelNameList = []\n",
    "for imodel in np.arange(0,21):\n",
    "    ModeName = 'CartesianModel0007_random%04d' %imodel\n",
    "    ModelNameList.append(ModeName)\n",
    "\n",
    "# wave dimension to animation\n",
    "output_channel = 'X'\n",
    "# wave_dim_s = output_channel.index('s')\n",
    "# wave_dim_p = output_channel.index('p')\n",
    "# wave_dim_z = output_channel.index('z')\n",
    "wave_dim_X = output_channel.index('X')\n",
    "\n",
    "for ModelName in ModelNameList:\n",
    "    # data_dir = '../Runs/%s/output/elements/orthogonal_azimuthal_slices' %ModelName\n",
    "    RunPath = '../Runs/%s' %ModelName\n",
    "\n",
    "    NETCDFDir = '../DataSet/%s' %ModelName\n",
    "    if not os.path.exists(NETCDFDir):\n",
    "        os.mkdir(NETCDFDir)\n",
    "    StationInfo = np.loadtxt(RunPath+'/input/Synthetic_Stations_Cartesian.txt',dtype=str, skiprows=3)\n",
    "    stalatlon_dict = {}\n",
    "    for item in StationInfo:\n",
    "        stkey = item[1]+'.'+item[0]\n",
    "        x = float(item[2])\n",
    "        y = float(item[3])\n",
    "        if stkey not in stalatlon_dict.keys():\n",
    "            stalatlon_dict[stkey] = []\n",
    "        stalatlon_dict[stkey].append((x, y))\n",
    "\n",
    "\n",
    "    StartTime, EndTime = 0, 1.5\n",
    "    resample_rate = 0.05\n",
    "    lowpass_freq = 20\n",
    "\n",
    "    PointPerTrace = int((EndTime - StartTime)/resample_rate)+1\n",
    "\n",
    "    istation = 0\n",
    "\n",
    "    if os.path.exists(NETCDFDir+'/seismogram.nc'):\n",
    "        os.remove(NETCDFDir+'/seismogram.nc')\n",
    "\n",
    "    nc = Dataset(NETCDFDir+'/seismogram.nc', 'w')\n",
    "    nc.createDimension('npoint', size=PointPerTrace*len(stalatlon_dict))\n",
    "    nc.createVariable('x', float, dimensions=('npoint'))\n",
    "    nc.createVariable('y', float, dimensions=('npoint'))\n",
    "    nc.createVariable('z', float, dimensions=('npoint'))\n",
    "    nc.createVariable('time', float, dimensions=('npoint'))\n",
    "    nc.createVariable('X', float, dimensions=('npoint'))\n",
    "\n",
    "\n",
    "    GSNDir = RunPath + '/output/stations/Synthetic_Stations'\n",
    "\n",
    "    # read rank-station info\n",
    "    rank_station_info = np.loadtxt(GSNDir + '/rank_station.info', dtype=str, skiprows=1)\n",
    "\n",
    "    # dict: mpi-rank -> [station keys]\n",
    "    rank_station_dict = {}\n",
    "    for item in rank_station_info:\n",
    "        rank = item[0]\n",
    "        stkey = item[1]\n",
    "        inrank_index = item[2]\n",
    "        # initialize with an empty array if rank does not exists in rank_station_dict\n",
    "        if rank not in rank_station_dict.keys():\n",
    "            rank_station_dict[rank] = []\n",
    "        # append the station\n",
    "        rank_station_dict[rank].append([stkey, inrank_index])\n",
    "        \n",
    "    # loop over mpi-ranks to read data\n",
    "    for rank in rank_station_dict.keys():\n",
    "        f = Dataset(GSNDir + '/axisem3d_synthetics.nc.rank%s' %rank, 'r')\n",
    "        time = f.variables['data_time'][:]\n",
    "\n",
    "        for [StationName, inrank_index] in rank_station_dict[rank]:\n",
    "            stax = stalatlon_dict[StationName][0][0]\n",
    "            stay = stalatlon_dict[StationName][0][1]\n",
    "            staz = 0\n",
    "\n",
    "            # trace header\n",
    "            stats = Stats()\n",
    "            stats.starttime = UTCDateTime(time[0])\n",
    "            stats.delta = UTCDateTime(time[1] - time[0])\n",
    "            stats.npts = len(time)\n",
    "\n",
    "            # stream\n",
    "            stream = Stream()\n",
    "            for ich, ch in enumerate(output_channel):\n",
    "                stats.channel = ch  \n",
    "                # default unit is km\n",
    "                stream.append(Trace(f.variables['data_wave'][int(inrank_index)][ich], header=stats))\n",
    "\n",
    "\n",
    "            stream.filter('lowpass', freq=lowpass_freq)\n",
    "            stream.resample(resample_rate)\n",
    "            # stream = stream.slice(UTCDateTime(int(arrivals[0].time)+StartTime), UTCDateTime(int(arrivals[0].time)+EndTime))\n",
    "            stream = stream.slice(UTCDateTime(StartTime), UTCDateTime(EndTime))\n",
    "            npoint_persta = len(stream[0].data)\n",
    "        \n",
    "            nc['x'][istation*npoint_persta:(istation+1)*npoint_persta] = stax\n",
    "            nc['y'][istation*npoint_persta:(istation+1)*npoint_persta] = stay\n",
    "            nc['z'][istation*npoint_persta:(istation+1)*npoint_persta] = staz\n",
    "\n",
    "            # nc['time'][istation*npoint_persta:(istation+1)*npoint_persta] = stream[0].times() + int(arrivals[0].time) + StartTime\n",
    "            nc['time'][istation*npoint_persta:(istation+1)*npoint_persta] = stream[0].times()\n",
    "\n",
    "            nc['X'][istation*npoint_persta:(istation+1)*npoint_persta] = stream[0].data\n",
    "\n",
    "            istation += 1\n",
    "\n",
    "    nc.close()\n",
    "\n",
    "    print(NETCDFDir+'/seismogram.nc', \" set up and saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npoint_persta\n",
    "PointPerTrace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/raid1/TomoNet/Runs/Sample/model0011/UnifromEarthCore.bm'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "# Move netcdf file\n",
    "# shutil.copy(RunPath+'/input/box_tomography.nc',NETCDFDir)\n",
    "shutil.copy(RunPath+'/tools/UnifromEarthCore.bm',NETCDFDir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b5da1a19760c645bef876c945e2def5171d007c0fd3f14585be32e516ddabd56"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
