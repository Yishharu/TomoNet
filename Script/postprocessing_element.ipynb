{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pyvtk\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from netCDF4 import Dataset\n",
    "import shutil\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data structure in element-wise output is too complicated for xarray.open_mfdataset.\n",
    "# Here we open the files as individual datasets and concatenate them on the variable level.\n",
    "# This code is compatible with parallel netcdf build (single file output)\n",
    "\n",
    "# load_wave_data=True:  read wave data and return numpy.ndarray\n",
    "# load_wave_data=False: do not read wave data and return xarray.DataArray (use False if data is big)\n",
    "\n",
    "def read_element_output(data_dir, load_wave_data=True):\n",
    "    ################ open files ################\n",
    "    # filenames\n",
    "    nc_fnames = [f for f in os.listdir(data_dir) if 'axisem3d_synthetics.nc' in f]\n",
    "    print('files to open: ', nc_fnames)\n",
    "\n",
    "    # open files\n",
    "    nc_files = []\n",
    "    for nc_fname in nc_fnames:\n",
    "        nc_files.append(xr.open_dataset(data_dir + '/' + nc_fname))\n",
    "    \n",
    "    ################ variables that are the same in the datasets ################\n",
    "    # read Na grid (all azimuthal dimensions)\n",
    "    na_grid = nc_files[0].data_vars['list_na_grid'].values.astype(int)\n",
    "\n",
    "    # read time\n",
    "    data_time = nc_files[0].data_vars['data_time'].values\n",
    "    \n",
    "    \n",
    "    ################ variables to be concatenated over the datasets ################\n",
    "    # define empty lists of xarray.DataArray objects\n",
    "    xda_list_element_na = []\n",
    "    xda_list_element_coords = []\n",
    "    dict_xda_list_element = {}\n",
    "    dict_xda_data_wave = {}\n",
    "    for nag in na_grid:\n",
    "        dict_xda_list_element[nag] = []\n",
    "        dict_xda_data_wave[nag] = []\n",
    "    \n",
    "    # loop over nc files\n",
    "    for nc_file in nc_files:\n",
    "        # append DataArrays\n",
    "        xda_list_element_na.append(nc_file.data_vars['list_element_na'])\n",
    "        xda_list_element_coords.append(nc_file.data_vars['list_element_coords'])\n",
    "        for nag in na_grid:\n",
    "            dict_xda_list_element[nag].append(nc_file.data_vars['list_element__NaG=%d' % nag])\n",
    "            dict_xda_data_wave[nag].append(nc_file.data_vars['data_wave__NaG=%d' % nag])\n",
    "            \n",
    "    # concat xarray.DataArray\n",
    "    xda_list_element_na = xr.concat(xda_list_element_na, dim='dim_element')\n",
    "    xda_list_element_coords = xr.concat(xda_list_element_coords, dim='dim_element')\n",
    "    for nag in na_grid:\n",
    "        dict_xda_list_element[nag] = xr.concat(dict_xda_list_element[nag], dim='dim_element__NaG=%d' % nag)\n",
    "        dict_xda_data_wave[nag] = xr.concat(dict_xda_data_wave[nag], dim='dim_element__NaG=%d' % nag)\n",
    "        \n",
    "    # read data to numpy.ndarray\n",
    "    list_element_na = xda_list_element_na.values.astype(int)\n",
    "    list_element_coords = xda_list_element_coords.values\n",
    "    dict_list_element = {}\n",
    "    dict_data_wave = {}\n",
    "    for nag in na_grid:\n",
    "        dict_list_element[nag] = dict_xda_list_element[nag].values.astype(int)\n",
    "        if load_wave_data:\n",
    "            dict_data_wave[nag] = dict_xda_data_wave[nag].values\n",
    "        \n",
    "    ############### return ################\n",
    "    if load_wave_data:\n",
    "        return na_grid, data_time, list_element_na, list_element_coords, dict_list_element, dict_data_wave\n",
    "    else:\n",
    "        return na_grid, data_time, list_element_na, list_element_coords, dict_list_element, dict_xda_data_wave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inplane slices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files to open:  ['axisem3d_synthetics.nc.rank4', 'axisem3d_synthetics.nc.rank14', 'axisem3d_synthetics.nc.rank23', 'axisem3d_synthetics.nc.rank22', 'axisem3d_synthetics.nc.rank5', 'axisem3d_synthetics.nc.rank0', 'axisem3d_synthetics.nc.rank18', 'axisem3d_synthetics.nc.rank12', 'axisem3d_synthetics.nc.rank16', 'axisem3d_synthetics.nc.rank1', 'axisem3d_synthetics.nc.rank10', 'axisem3d_synthetics.nc.rank11', 'axisem3d_synthetics.nc.rank3', 'axisem3d_synthetics.nc.rank19', 'axisem3d_synthetics.nc.rank15', 'axisem3d_synthetics.nc.rank20', 'axisem3d_synthetics.nc.rank9', 'axisem3d_synthetics.nc.rank7', 'axisem3d_synthetics.nc.rank13', 'axisem3d_synthetics.nc.rank17', 'axisem3d_synthetics.nc.rank2', 'axisem3d_synthetics.nc.rank21', 'axisem3d_synthetics.nc.rank6', 'axisem3d_synthetics.nc.rank8']\n",
      "Done time step 118 / 118\n",
      "Done slice 1 / 4\n",
      "Done time step 118 / 118\n",
      "Done slice 2 / 4\n",
      "Done time step 118 / 118\n",
      "Done slice 3 / 4\n",
      "Done time step 118 / 118\n",
      "Done slice 4 / 4\n",
      "../Runs/CartesianModel0005/output/elements/orthogonal_azimuthal_slices/netcdf/ ../DataSet/CartesianModel0005/snapshot\n",
      "files to open:  ['axisem3d_synthetics.nc.rank4', 'axisem3d_synthetics.nc.rank14', 'axisem3d_synthetics.nc.rank23', 'axisem3d_synthetics.nc.rank22', 'axisem3d_synthetics.nc.rank5', 'axisem3d_synthetics.nc.rank0', 'axisem3d_synthetics.nc.rank18', 'axisem3d_synthetics.nc.rank12', 'axisem3d_synthetics.nc.rank16', 'axisem3d_synthetics.nc.rank1', 'axisem3d_synthetics.nc.rank10', 'axisem3d_synthetics.nc.rank11', 'axisem3d_synthetics.nc.rank3', 'axisem3d_synthetics.nc.rank19', 'axisem3d_synthetics.nc.rank15', 'axisem3d_synthetics.nc.rank20', 'axisem3d_synthetics.nc.rank9', 'axisem3d_synthetics.nc.rank7', 'axisem3d_synthetics.nc.rank13', 'axisem3d_synthetics.nc.rank17', 'axisem3d_synthetics.nc.rank2', 'axisem3d_synthetics.nc.rank21', 'axisem3d_synthetics.nc.rank6', 'axisem3d_synthetics.nc.rank8']\n",
      "Done time step 118 / 118\n",
      "Done slice 1 / 4\n",
      "Done time step 118 / 118\n",
      "Done slice 2 / 4\n",
      "Done time step 118 / 118\n",
      "Done slice 3 / 4\n",
      "Done time step 118 / 118\n",
      "Done slice 4 / 4\n",
      "../Runs/CartesianModel0006/output/elements/orthogonal_azimuthal_slices/netcdf/ ../DataSet/CartesianModel0006/snapshot\n"
     ]
    }
   ],
   "source": [
    "# data dir\n",
    "ModelNameList = ['CartesianModel0005','CartesianModel0006']\n",
    "\n",
    "# wave dimension to animation\n",
    "output_channel = 'X'\n",
    "# wave_dim_s = output_channel.index('s')\n",
    "# wave_dim_p = output_channel.index('p')\n",
    "# wave_dim_z = output_channel.index('z')\n",
    "wave_dim_X = output_channel.index('X')\n",
    "\n",
    "\n",
    "for ModelName in ModelNameList:\n",
    "    data_dir = '../Runs/%s/output/elements/orthogonal_azimuthal_slices' %ModelName\n",
    "\n",
    "    # read\n",
    "    na_grid, data_time, list_element_na, list_element_coords, \\\n",
    "    dict_list_element, dict_data_wave = read_element_output(data_dir)\n",
    "\n",
    "\n",
    "\n",
    "    # time steps\n",
    "    ntime = len(data_time)\n",
    "\n",
    "    # phi of the slices\n",
    "    # phi_slices = [0.        , 0.01745329, 0.03490659, 0.05235988, 0.06981317, 0.08726646, 6.19591884, 6.21337214, 6.23082543, 6.24827872, 6.26573201]\n",
    "    # phi_slices= [0.        , 0.17453293, 0.34906585, 0.52359878, 0.6981317, 0.87266463, 1.04719755, 1.22173048, 1.3962634, 1.57079633, 1.74532925, 1.91986218, 2.0943951 , 2.26892803, 2.44346095, 2.61799388, 2.7925268 , 2.96705973, 3.14159265, 3.31612558, 3.4906585, 3.66519143, 3.83972435, 4.01425728, 4.1887902, 4.36332313, 4.53785606, 4.71238898, 4.88692191, 5.06145483, 5.23598776, 5.41052068, 5.58505361, 5.75958653, 5.93411946, 6.10865238]\n",
    "    phi_slices = [0.        , 1.57079633, 3.14159265, 4.71238898]\n",
    "    nslice = len(phi_slices)\n",
    "\n",
    "    # GLL coords on elements\n",
    "    nelem = list_element_coords.shape[0]\n",
    "    ngll = list_element_coords.shape[1]\n",
    "    # flattened coords, (s, z)\n",
    "    element_coords_sz = list_element_coords.reshape((nelem * ngll), 2)\n",
    "\n",
    "    # connectivity list, shared by all slices\n",
    "    # with GLL_points_one_edge = [0, 2, 4] in the inparam.output.yaml,\n",
    "    # the GLL point layout on each element is\n",
    "    # 0--1--2\n",
    "    # |  |  |\n",
    "    # 3--4--5\n",
    "    # |  |  |\n",
    "    # 6--7--8\n",
    "    # connectivity = []\n",
    "\n",
    "\n",
    "    # for ielem in np.arange(nelem):\n",
    "    #     start = ielem * 9\n",
    "    #     connectivity.append([start + 0, start + 1, start + 4, start + 3])\n",
    "    #     connectivity.append([start + 1, start + 2, start + 5, start + 4])\n",
    "    #     connectivity.append([start + 3, start + 4, start + 7, start + 6])\n",
    "    #     connectivity.append([start + 4, start + 5, start + 8, start + 7])\n",
    "\n",
    "    # loop over slices\n",
    "    for islice, phi in enumerate(phi_slices):\n",
    "        # create vtk folder\n",
    "        # NETCDFDir = data_dir + '/netcdf/slice%d' % islice\n",
    "        # os.makedirs(NETCDFDir, exist_ok=True)\n",
    "\n",
    "        # nc = Dataset(NETCDFDir+'/%s/seismogram.nc' %EventName, 'w')\n",
    "        # nc.createDimension('npoint', size=7199)\n",
    "        \n",
    "        # vtk mesh\n",
    "        xyz = np.ndarray((nelem * ngll, 3))\n",
    "        xyz[:, 0] = element_coords_sz[:, 0] * np.cos(phi)\n",
    "        xyz[:, 1] = element_coords_sz[:, 0] * np.sin(phi)\n",
    "        xyz[:, 2] = element_coords_sz[:, 1]\n",
    "\n",
    "        # loop over elements to read wave data\n",
    "        wave_s = np.ndarray((nelem * ngll, ntime))\n",
    "        wave_p = np.ndarray((nelem * ngll, ntime))\n",
    "        wave_z = np.ndarray((nelem * ngll, ntime))\n",
    "        wave_X = np.ndarray((nelem * ngll, ntime))\n",
    "\n",
    "\n",
    "        for ielem in np.arange(nelem):\n",
    "            # wave_s[(ielem * ngll):(ielem * ngll + ngll), :] = dict_data_wave[nslice][ielem, islice, :, wave_dim_s, :]\n",
    "            # wave_p[(ielem * ngll):(ielem * ngll + ngll), :] = dict_data_wave[nslice][ielem, islice, :, wave_dim_p, :]\n",
    "            # wave_z[(ielem * ngll):(ielem * ngll + ngll), :] = dict_data_wave[nslice][ielem, islice, :, wave_dim_z, :]\n",
    "            wave_X[(ielem * ngll):(ielem * ngll + ngll), :] = dict_data_wave[nslice][ielem, islice, :, wave_dim_X, :]\n",
    "        \n",
    "        # loop over time to write netcdf\n",
    "        for itime in np.arange(ntime):\n",
    "            \n",
    "            NETCDFDir = data_dir + '/netcdf/snapshot%d' % itime\n",
    "            os.makedirs(NETCDFDir, exist_ok=True)\n",
    "\n",
    "            nc = Dataset(NETCDFDir+'/slice%d.nc' %islice, 'w')\n",
    "            nc.createDimension('npoint', size=len(xyz))\n",
    "            nc.createDimension('3D', size=3)\n",
    "\n",
    "            nc.createVariable('x', float, dimensions=('npoint'))\n",
    "            nc['x'][:] = xyz[:,0]\n",
    "            nc.createVariable('y', float, dimensions=('npoint'))\n",
    "            nc['y'][:] = xyz[:,1]\n",
    "            nc.createVariable('z', float, dimensions=('npoint'))\n",
    "            nc['z'][:] = xyz[:,2]\n",
    "            nc.createVariable('time', float, dimensions=('npoint'))\n",
    "            nc['time'][:] = np.ones(len(xyz))*data_time[itime]\n",
    "\n",
    "            # convert spz to xyz coordinate frame by formula 3.9 Leng thesis page 28\n",
    "            nc.createVariable('disp_x', float, dimensions=('npoint'))\n",
    "            nc['disp_x'][:] = wave_s[:,itime] * np.cos(phi) - wave_p[:,itime] * np.sin(phi)\n",
    "            nc.createVariable('disp_y', float, dimensions=('npoint'))\n",
    "            nc['disp_y'][:] = wave_s[:,itime] * np.sin(phi) + wave_p[:,itime] * np.cos(phi)\n",
    "            nc.createVariable('disp_z', float, dimensions=('npoint'))\n",
    "            nc['disp_z'][:] = wave_z[:,itime]\n",
    "            nc.createVariable('X', float, dimensions=('npoint'))\n",
    "            nc['X'][:] = wave_X[:,itime]\n",
    "\n",
    "\n",
    "            nc.close()\n",
    "\n",
    "            print('Done time step %d / %d' % (itime + 1, ntime), end='\\r')\n",
    "        print('\\nDone slice %d / %d' % (islice + 1, len(phi_slices)))\n",
    "\n",
    "    # Check Repeated Dataset\n",
    "    if os.path.exists('../DataSet/%s/' %ModelName):\n",
    "        shutil.rmtree('../DataSet/%s/' %ModelName)\n",
    "\n",
    "    # Initial Model Folder\n",
    "    os.makedirs('../DataSet/%s/' %ModelName, exist_ok=True)\n",
    "\n",
    "    # Check 3D model nc file\n",
    "    NCFilePath = glob.glob('../Runs/%s/input/*.nc' %ModelName)\n",
    "    if len(NCFilePath) > 0:\n",
    "        for path in NCFilePath:\n",
    "            shutil.copy(path, '../DataSet/%s/' %ModelName)\n",
    "\n",
    "    shutil.move(data_dir + '/netcdf/', '../DataSet/%s/snapshot' %ModelName)\n",
    "\n",
    "    print(data_dir + '/netcdf/', '../DataSet/%s/snapshot' %ModelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 1.57079633, 3.14159265, 4.71238898])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.radians(np.arange(0,360,10));\n",
    "np.radians(np.arange(0,360,90))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b5da1a19760c645bef876c945e2def5171d007c0fd3f14585be32e516ddabd56"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
