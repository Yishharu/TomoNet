{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pyvtk\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_element_output(data_dir, load_wave_data=True):\n",
    "    ################ open files ################\n",
    "    # filenames\n",
    "    nc_fnames = [f for f in os.listdir(data_dir) if 'axisem3d_synthetics.nc' in f]\n",
    "    print('files to open: ', nc_fnames)\n",
    "\n",
    "    # open files\n",
    "    nc_files = []\n",
    "    for nc_fname in nc_fnames:\n",
    "        nc_files.append(xr.open_dataset(data_dir + '/' + nc_fname))\n",
    "\n",
    "    ################ variables that are the same in the datasets ################\n",
    "    # read Na grid (all azimuthal dimensions)\n",
    "    na_grid = nc_files[0].data_vars['list_na_grid'].values.astype(int)\n",
    "\n",
    "    # read time\n",
    "    data_time = nc_files[0].data_vars['data_time'].values\n",
    "\n",
    "    ################ variables to be concatenated over the datasets ################\n",
    "    # define empty lists of xarray.DataArray objects\n",
    "    xda_list_element_na = []\n",
    "    xda_list_element_coords = []\n",
    "    dict_xda_list_element = {}\n",
    "    dict_xda_data_wave = {}\n",
    "    for nag in na_grid:\n",
    "        dict_xda_list_element[nag] = []\n",
    "        dict_xda_data_wave[nag] = []\n",
    "\n",
    "    # loop over nc files\n",
    "    for nc_file in nc_files:\n",
    "        # append DataArrays\n",
    "        xda_list_element_na.append(nc_file.data_vars['list_element_na'])\n",
    "        xda_list_element_coords.append(nc_file.data_vars['list_element_coords'])\n",
    "        for nag in na_grid:\n",
    "            dict_xda_list_element[nag].append(nc_file.data_vars['list_element__NaG=%d' % nag])\n",
    "            dict_xda_data_wave[nag].append(nc_file.data_vars['data_wave__NaG=%d' % nag])\n",
    "\n",
    "    # concat xarray.DataArray\n",
    "    xda_list_element_na = xr.concat(xda_list_element_na, dim='dim_element')\n",
    "    xda_list_element_coords = xr.concat(xda_list_element_coords, dim='dim_element')\n",
    "    for nag in na_grid:\n",
    "        dict_xda_list_element[nag] = xr.concat(dict_xda_list_element[nag], dim='dim_element__NaG=%d' % nag)\n",
    "        dict_xda_data_wave[nag] = xr.concat(dict_xda_data_wave[nag], dim='dim_element__NaG=%d' % nag)\n",
    "\n",
    "    # read data to numpy.ndarray\n",
    "    list_element_na = xda_list_element_na.values.astype(int)\n",
    "    list_element_coords = xda_list_element_coords.values\n",
    "    dict_list_element = {}\n",
    "    dict_data_wave = {}\n",
    "    for nag in na_grid:\n",
    "        dict_list_element[nag] = dict_xda_list_element[nag].values.astype(int)\n",
    "        if load_wave_data:\n",
    "            dict_data_wave[nag] = dict_xda_data_wave[nag].values\n",
    "\n",
    "    ############### return ################\n",
    "    if load_wave_data:\n",
    "        return na_grid, data_time, list_element_na, list_element_coords, dict_list_element, dict_data_wave\n",
    "    else:\n",
    "        return na_grid, data_time, list_element_na, list_element_coords, dict_list_element, dict_xda_data_wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  CartesianDeepRandomModel0000\n",
      "files to open:  ['axisem3d_synthetics.nc.rank4', 'axisem3d_synthetics.nc.rank14', 'axisem3d_synthetics.nc.rank23', 'axisem3d_synthetics.nc.rank22', 'axisem3d_synthetics.nc.rank5', 'axisem3d_synthetics.nc.rank0', 'axisem3d_synthetics.nc.rank18', 'axisem3d_synthetics.nc.rank12', 'axisem3d_synthetics.nc.rank16', 'axisem3d_synthetics.nc.rank1', 'axisem3d_synthetics.nc.rank10', 'axisem3d_synthetics.nc.rank11', 'axisem3d_synthetics.nc.rank3', 'axisem3d_synthetics.nc.rank19', 'axisem3d_synthetics.nc.rank15', 'axisem3d_synthetics.nc.rank20', 'axisem3d_synthetics.nc.rank9', 'axisem3d_synthetics.nc.rank7', 'axisem3d_synthetics.nc.rank13', 'axisem3d_synthetics.nc.rank17', 'axisem3d_synthetics.nc.rank2', 'axisem3d_synthetics.nc.rank21', 'axisem3d_synthetics.nc.rank6', 'axisem3d_synthetics.nc.rank8']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "arguments without labels along dimension 'dim_channel' cannot be aligned because they have different dimension sizes: {1, 5}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 13\u001b[0m\n\u001b[1;32m      9\u001b[0m data_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../Runs/\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m/output/elements/orthogonal_azimuthal_slices\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39mModelName\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# read\u001b[39;00m\n\u001b[1;32m     12\u001b[0m na_grid, data_time, list_element_na, list_element_coords, \\\n\u001b[0;32m---> 13\u001b[0m dict_list_element, dict_data_wave \u001b[38;5;241m=\u001b[39m \u001b[43mread_element_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# wave dimension to animation\u001b[39;00m\n\u001b[1;32m     16\u001b[0m wave_channel \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "Cell \u001b[0;32mIn[25], line 43\u001b[0m, in \u001b[0;36mread_element_output\u001b[0;34m(data_dir, load_wave_data)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m nag \u001b[38;5;129;01min\u001b[39;00m na_grid:\n\u001b[1;32m     42\u001b[0m     dict_xda_list_element[nag] \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mconcat(dict_xda_list_element[nag], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdim_element__NaG=\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m nag)\n\u001b[0;32m---> 43\u001b[0m     dict_xda_data_wave[nag] \u001b[38;5;241m=\u001b[39m \u001b[43mxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdict_xda_data_wave\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnag\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdim_element__NaG=\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnag\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# read data to numpy.ndarray\u001b[39;00m\n\u001b[1;32m     46\u001b[0m list_element_na \u001b[38;5;241m=\u001b[39m xda_list_element_na\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/xarray/core/concat.py:242\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, dim, data_vars, coords, compat, positions, fill_value, join, combine_attrs)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    238\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    239\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcan only concatenate xarray Dataset and DataArray \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    240\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mobjects, got \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(first_obj)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    241\u001b[0m     )\n\u001b[0;32m--> 242\u001b[0m \u001b[39mreturn\u001b[39;00m f(\n\u001b[1;32m    243\u001b[0m     objs, dim, data_vars, coords, compat, positions, fill_value, join, combine_attrs\n\u001b[1;32m    244\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/xarray/core/concat.py:582\u001b[0m, in \u001b[0;36m_dataarray_concat\u001b[0;34m(arrays, dim, data_vars, coords, compat, positions, fill_value, join, combine_attrs)\u001b[0m\n\u001b[1;32m    579\u001b[0m             arr \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mrename(name)\n\u001b[1;32m    580\u001b[0m     datasets\u001b[39m.\u001b[39mappend(arr\u001b[39m.\u001b[39m_to_temp_dataset())\n\u001b[0;32m--> 582\u001b[0m ds \u001b[39m=\u001b[39m _dataset_concat(\n\u001b[1;32m    583\u001b[0m     datasets,\n\u001b[1;32m    584\u001b[0m     dim,\n\u001b[1;32m    585\u001b[0m     data_vars,\n\u001b[1;32m    586\u001b[0m     coords,\n\u001b[1;32m    587\u001b[0m     compat,\n\u001b[1;32m    588\u001b[0m     positions,\n\u001b[1;32m    589\u001b[0m     fill_value\u001b[39m=\u001b[39;49mfill_value,\n\u001b[1;32m    590\u001b[0m     join\u001b[39m=\u001b[39;49mjoin,\n\u001b[1;32m    591\u001b[0m     combine_attrs\u001b[39m=\u001b[39;49mcombine_attrs,\n\u001b[1;32m    592\u001b[0m )\n\u001b[1;32m    594\u001b[0m merged_attrs \u001b[39m=\u001b[39m merge_attrs([da\u001b[39m.\u001b[39mattrs \u001b[39mfor\u001b[39;00m da \u001b[39min\u001b[39;00m arrays], combine_attrs)\n\u001b[1;32m    596\u001b[0m result \u001b[39m=\u001b[39m arrays[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39m_from_temp_dataset(ds, name)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/xarray/core/concat.py:442\u001b[0m, in \u001b[0;36m_dataset_concat\u001b[0;34m(datasets, dim, data_vars, coords, compat, positions, fill_value, join, combine_attrs)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[39m# Make sure we're working on a copy (we'll be loading variables)\u001b[39;00m\n\u001b[1;32m    440\u001b[0m datasets \u001b[39m=\u001b[39m [ds\u001b[39m.\u001b[39mcopy() \u001b[39mfor\u001b[39;00m ds \u001b[39min\u001b[39;00m datasets]\n\u001b[1;32m    441\u001b[0m datasets \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\n\u001b[0;32m--> 442\u001b[0m     align(\u001b[39m*\u001b[39;49mdatasets, join\u001b[39m=\u001b[39;49mjoin, copy\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, exclude\u001b[39m=\u001b[39;49m[dim], fill_value\u001b[39m=\u001b[39;49mfill_value)\n\u001b[1;32m    443\u001b[0m )\n\u001b[1;32m    445\u001b[0m dim_coords, dims_sizes, coord_names, data_names \u001b[39m=\u001b[39m _parse_datasets(datasets)\n\u001b[1;32m    446\u001b[0m dim_names \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(dim_coords)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/xarray/core/alignment.py:348\u001b[0m, in \u001b[0;36malign\u001b[0;34m(join, copy, indexes, exclude, fill_value, *objects)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[39mfor\u001b[39;00m dim, sizes \u001b[39min\u001b[39;00m unlabeled_dim_sizes\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    347\u001b[0m     \u001b[39mif\u001b[39;00m dim \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m all_indexes \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(sizes) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 348\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    349\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39marguments without labels along dimension \u001b[39m\u001b[39m{\u001b[39;00mdim\u001b[39m!r}\u001b[39;00m\u001b[39m cannot be \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    350\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39maligned because they have different dimension sizes: \u001b[39m\u001b[39m{\u001b[39;00msizes\u001b[39m!r}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    351\u001b[0m         )\n\u001b[1;32m    353\u001b[0m result \u001b[39m=\u001b[39m []\n\u001b[1;32m    354\u001b[0m \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m objects:\n\u001b[1;32m    355\u001b[0m     \u001b[39m# TODO: benbovy - flexible indexes: https://github.com/pydata/xarray/issues/5647\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: arguments without labels along dimension 'dim_channel' cannot be aligned because they have different dimension sizes: {1, 5}"
     ]
    }
   ],
   "source": [
    "ModelNameList = []\n",
    "for imodel in np.arange(0,1):\n",
    "    ModeName = 'CartesianDeepRandomModel%04d' %imodel\n",
    "    ModelNameList.append(ModeName)\n",
    "\n",
    "for ModelName in ModelNameList:\n",
    "    print('Processing ', ModelName)\n",
    "    # data dir\n",
    "    data_dir = '../Runs/%s/output/elements/orthogonal_azimuthal_slices' %ModelName\n",
    "\n",
    "    # read\n",
    "    na_grid, data_time, list_element_na, list_element_coords, \\\n",
    "    dict_list_element, dict_data_wave = read_element_output(data_dir)\n",
    "\n",
    "    # wave dimension to animation\n",
    "    wave_channel = 'X'\n",
    "    wave_dim = 'X'.index(wave_channel)\n",
    "\n",
    "    # time steps\n",
    "    ntime = len(data_time)\n",
    "\n",
    "    # phi of the slices\n",
    "    phi_slices = np.radians(np.arange(0,360,400))\n",
    "    nslice = len(phi_slices)\n",
    "\n",
    "    # GLL coords on elementsnslice\n",
    "    nelem = list_element_coords.shape[0]\n",
    "    ngll = list_element_coords.shape[1]\n",
    "    # flattened coords, (s, z)\n",
    "    element_coords_sz = list_element_coords.reshape((nelem * ngll), 2)\n",
    "\n",
    "    # connectivity list, shared by all slices\n",
    "    # with GLL_points_one_edge = [0, 2, 4] in the inparam.output.yaml,\n",
    "    # the GLL point layout on each element is\n",
    "    # 0--1\n",
    "    # |  |\n",
    "    # 2--3\n",
    "    # connectivity = []\n",
    "    # for ielem in np.arange(nelem):\n",
    "    #     start = ielem * 4\n",
    "    #     connectivity.append([start + 0, start + 1, start + 3, start + 2])\n",
    "\n",
    "    # connectivity list, shared by all slices\n",
    "    # with GLL_points_one_edge = [0, 2, 4] in the inparam.output.yaml,\n",
    "    # the GLL point layout on each element is\n",
    "    # 0--1--2\n",
    "    # |  |  |\n",
    "    # 3--4--5\n",
    "    # |  |  |\n",
    "    # 6--7--8\n",
    "    # connectivity = []\n",
    "    # for ielem in np.arange(nelem):\n",
    "    #     start = ielem * 9\n",
    "    #     connectivity.append([start + 0, start + 1, start + 4, start + 3])\n",
    "    #     connectivity.append([start + 1, start + 2, start + 5, start + 4])\n",
    "    #     connectivity.append([start + 3, start + 4, start + 7, start + 6])\n",
    "    #     connectivity.append([start + 4, start + 5, start + 8, start + 7])\n",
    "\n",
    "    # with GLL_points_one_edge = [0,1,2,3,4] in the inparam.output.yaml,\n",
    "    # the GLL point layout on each element is\n",
    "    # 0--1--2--3--4\n",
    "    # |  |  |\n",
    "    # 5--6--7--8--9\n",
    "    # |  |  |\n",
    "    # 10--11--12--13--14\n",
    "    # 15--16--17--18--19\n",
    "    # 20--21--22--23--24\n",
    "    connectivity = []\n",
    "    for ielem in np.arange(nelem):\n",
    "        start = ielem * 25\n",
    "        connectivity.append([start + 0, start + 1, start + 6, start + 5])\n",
    "        connectivity.append([start + 1, start + 2, start + 7, start + 6])\n",
    "        connectivity.append([start + 2, start + 3, start + 8, start + 7])\n",
    "        connectivity.append([start + 3, start + 4, start + 9, start + 8])\n",
    "        connectivity.append([start + 5, start + 6, start + 11, start + 10])\n",
    "        connectivity.append([start + 6, start + 7, start + 12, start + 11])\n",
    "        connectivity.append([start + 7, start + 8, start + 13, start + 12])\n",
    "        connectivity.append([start + 8, start + 9, start + 14, start + 13])\n",
    "        connectivity.append([start + 10, start + 11, start + 16, start + 15])\n",
    "        connectivity.append([start + 11, start + 12, start + 17, start + 16])\n",
    "        connectivity.append([start + 12, start + 13, start + 18, start + 17])\n",
    "        connectivity.append([start + 13, start + 14, start + 19, start + 18])\n",
    "        connectivity.append([start + 15, start + 16, start + 21, start + 20])\n",
    "        connectivity.append([start + 16, start + 17, start + 22, start + 21])\n",
    "        connectivity.append([start + 17, start + 18, start + 23, start + 22])\n",
    "        connectivity.append([start + 18, start + 19, start + 24, start + 23])\n",
    "\n",
    "    # loop over slices\n",
    "    for islice, phi in enumerate(phi_slices[0:1]):\n",
    "        # create vtk folder\n",
    "        vtk_dir = data_dir + '/vtk_%s/slice%d' % (wave_channel, islice)\n",
    "        os.makedirs(vtk_dir, exist_ok=True)\n",
    "\n",
    "        # vtk mesh\n",
    "        xyz = np.ndarray((nelem * ngll, 3))\n",
    "        xyz[:, 0] = element_coords_sz[:, 0] * np.cos(phi)\n",
    "        xyz[:, 1] = element_coords_sz[:, 0] * np.sin(phi)\n",
    "        xyz[:, 2] = element_coords_sz[:, 1]\n",
    "        vtk_mesh = pyvtk.UnstructuredGrid(list(zip(xyz[:, 0], xyz[:, 1], xyz[:, 2])),\n",
    "                                        quad=connectivity)\n",
    "\n",
    "        # loop over elements to read wave data\n",
    "        wave = np.ndarray((nelem * ngll, ntime))\n",
    "        for ielem in np.arange(nelem):\n",
    "            wave[(ielem * ngll):(ielem * ngll + ngll), :] = dict_data_wave[nslice][ielem, islice, :, wave_dim, :]\n",
    "\n",
    "        # loop over time to write vtk\n",
    "        for itime in np.arange(ntime):\n",
    "            vtk = pyvtk.VtkData(vtk_mesh, pyvtk.PointData(pyvtk.Scalars(wave[:, itime], name='U' + wave_channel)))\n",
    "            vtk.tofile(vtk_dir + '/' + 'wave%d.vtk' % itime, 'binary')\n",
    "            print('Done time step %d / %d' % (itime + 1, ntime), end='\\r')\n",
    "        print('\\nDone slice %d' % (islice + 1))\n",
    "\n",
    "        print(ModelName, ' wavefield value in ', [np.min(wave[:,-1]), np.max(wave[:,-1])])\n",
    "        if np.max(wave[:,-1])>1e-3:\n",
    "            print(ModelName, ' Attention !!!!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wavefield value in  [-8.323135930465853e-11, 5.0449568134158795e-11]\n"
     ]
    }
   ],
   "source": [
    "print('wavefield value in ', [np.min(wave[:,-1]), np.max(wave[:,-1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wave_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b5da1a19760c645bef876c945e2def5171d007c0fd3f14585be32e516ddabd56"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
